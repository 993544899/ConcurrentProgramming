# 第一章 并发程序设计总论
* 1.1问题分析
* 1.2分工原则
* 1.3有效的并发策略
* 1.4小结
  
大家对并发(concurrency)、多线程(Multi-Threading)程序设计肯定不陌生，因为在当今多核CPU时代到处可见，从底层的操作系统(OS)到上层的应用程序，从服务端到客户端，从低级语言到高级程序语言、从分布式集群到大数据处理等等，都可以看到并发程序的身影。可以这样说，只要有计算机软件的地方，就会存在并发程序。大家肯定知道，为何到处都有并发程序？就是因为它能够加快我们程序的运行速度，减少运行时间，从而提高软件的性能，更快地响应用户，以达到更好的用户体验。大家肯定见到过人们为了吃饭、办理银行业务而耐心等待，却经常因为打开网页慢或软件运行慢而感到抓狂，如果这个网站或软件对提供商来说无关紧要那也许没什么问题，但是如果这网站或软件要为了盈利或者有更远大的理想，那有时候可能是致命，因为人们很可能因为慢，下次再也不来访问网站或使用软件。所以，并发程序使得程序运行更快，更快速响应客户操作，从而使软件产品的用户体验提高了，这将会带来更好的经济效益。因此，并发程序设计在软件开发中才会运用得如此广泛。但是，您真的了解并发程序设计么？您可能认为，并发程序设计不就是按照很多操作系统或平台(Java或.NET等)及语言(java,C#,ruby,scala,go等)提供的类(Thread)、框架(akka等)、设计方法(共享变量，软件事务内存[STM]、actor)及并发模式与模型(reactor、proactor、selector、poll、epoll)来开发，主要处理好线程同步的问题就应该差不多了，其他的都是具体实现细节问题。不错，但是您说的只是并发程序设计的具体实现技术，也是我们在设计与开发并发程序时具体应用并需要掌握的技术，但是这些只是战术，是具体实现。不是战略或设计策略，不是指导思想。那么我们就先从并发程序设计的战略或策略层面开始讨论如何进行并发程序设计，这些方法与具体平台或语言无关，可以在各种平台上用具体语言去实现，后面再讨论具体的实现技术与框架，以便能做到战略与战术相结合，这样才能真正掌握并发程序设计。
# 1.1问题分析 
在做很多事情之前，都应该对现有问题进行具体分析，以便能更好的把握问题，进行合理适当的设计。当然，我们在进行并发程序设计时也应该如此。那么在并发程序设计之前，通常需要分析问题的哪些方面呢？大家都知道，设计并发程序的目的就是为了使程序运行得更快（时间就是金钱、生命），提高软件的性能。并发程序之所以能快，就在于这个“并”字，因为程序能并发(单核)或并行(多核、多CPU)执行，当然能快。这就好比工人搬砖块，人当然是越多越快。但是，这之中有个关键问题，大家是否想到，那就是这个事情（如搬砖块）可以并发或并行来做。又例如每个人乘车去上班这件事就没法并发来做，因为从起点到终点，公交车只能是一站一站到达，同一辆不可能同时达到几个站，也不可能给你增加几台公交车(多核，多线程)，你的乘车时间因此减少了，所以这个时候，给你再多的车(增加CPU或核心数)，你的乘车时间也不会减少（程序性能提高不了），因此这个时候，你只能希望汽车跑得更快（提高单个CPU或核心的运算速度），这样才能达到减少时间提高程序性能的目的。这就说明了，并发程序设计的一个本质问题，就是首先要分析问题能不能让程序去并发或并行执行？如果这个问题(乘公交车上班)本身就只能串行去做，那么您就不用考虑使用并发编程技术了，因为这不但不能提高效率反而会使程序开发变得更加复杂，得不偿失。如果这个问题可以并发执行，并发程序当然能提高程序的性能，但是我们也不能高兴的太早，认为只要是这种情况，我就要立即运用并发编程技术，也不考虑编程的复杂性及掉头发的危险，反正就是为了程序运行速度提高0.001秒的那种快感（真正在设计并发程序时需要权衡很多因素，这些以后的章节中具体讨论）。在确定需要使用并发编程技术来解决问题后，我们应该进一步分解问题，其实现实世界中广泛存在两类可以并发处理的问题场景：一种是可以完全并发或并行（如访问网站，银行窗口办业务等），这当然是绝佳的并发编程应用场景；还有一种则是总体需要串行，但中间有些步骤可以并发执行(事实上所有能并发处理的问题都是这种类型，只是看具体问题规模及分解情况)，这个时候就需要处理依赖（前置步骤）与等待(同步)问题，最终按顺序完成。所以我们需要把问题进行逐步分解，以便最大化利用并发编程的优势。
我们知道，当引入并发程序解决问题时，目的是为了加快程序运行速度，减少时间。但是你肯定想知道快了多少，是否达到你的预期。这个数据不难得出，只要在同等条件下，把并发之前与之后的程序运行时间对照一下就能看出来。通常人们把程序优化之前运行时间与优化之后的时间的比值称之程序加速比。它是用来衡量程序优化效果的一个关键参数。
程序加速比 = 优化前耗时 / 优化后耗时
从上述的说明中，可以得知在同等条件下影响加速比的两个因素是：问题的可并行化程度与CPU个数或核心数，其中问题的可并行化程度，可简单理解为问题中可以并行部分与串行部分的比重(如某问题一共需要5步完成，其中有2步可以并行其余3步必须串行，那么该问题的可并行化程度为2/5)。另外，这里需要说明一下，什么是同等条件，简单地说就是优化前与优化后的程序是在相同环境（问题不变，CPU计算速度不变）中运行。因为如果不在同等条件下比较的话就失去一般性意义，看不到问题的本质，当你把程序从低性能的CPU转向高性能的CPU上运行时，当然也能提高加速比，但是你可能很难看出可并行化程度与CPU个数或核心数跟加速比之间的内在联系。由此，我们引入计算机科学中非常重要的定律——Amdahl定律。它定义了串行系统并行化后加速比的计算公式与理论上限，并给出了加速比与系统并行程度和处理器(CPU)数量的关系。设加速比为Speedup,系统内必须串行化的部分比重为F，CPU数量为N，则有公式：
Speedup≤1/(F+(1-F)/N)
当处理器(CPU)的数量N 趋于无穷大时，Speedup 的最大值无限趋近1/F ，那么加速比与系统的串行化率成反比。这意味着如果程序中有50%(F)的处理都需要串行进行的话，Speedup 只能提升2倍；如果程序中有10%(F)需要串行进行，Speedup 最多能够提高近10倍。
Amdahl定律同样量化了串行化的效率开销。在拥有10个处理器的系统中，程序如果有10%是串行化的，那么最多可以加速5.3倍（53％的使用率），在拥有100个处理器的系统中，这个数字可以达到9.2（9％的使用率）。即使有无限多个CPU(N)，程序加速比也不可能为10。
我们可以通过下面示例来说明，假设某一程序分为5个步骤执行，每个执行步骤耗时10秒。其中，只有步骤2与步骤5可以并行执行，步骤1、3、4必须串行，如图1.1所示，该程序在全串行的情况下总耗时为50秒。


图1.1
若将步骤2与步骤5并行执行，假设在双核处理器上，则有如图1.2所示的处理流程。在这种情况下，步骤2与步骤5分别耗时5秒。根据加速比定义：加速比 = 优化前耗时 / 优化后耗时 = 50 / 40 = 1.25，或者我们再用Amdahl公式计算加速比，由于5个步骤中，有3个步骤需要串行化执行，则该程序的串行化比重(F)为3/5(即0.6)，且处理器为双核CPU，即N为2。代入公式得：加速比 = 1/(0.6+(1-0.6)/2) = 1/0.8 = 1.25。




图1.2
现在我们再假设处理器个数(N)为无穷大，则如图1.3所示，步骤2与5的执行时间接近于0，但即使是这样，程序的总体执行时间仍然大于30秒，即加速比的极限为：50/30 = 1.67。使用Amdahl公式同样可以得出加速比为：1/F = 1/0.6 = 1.67。





图1.3
由此可见，为了提高系统的运行速度，减少执行时间，仅仅依靠增加处理器(CPU或核心数)数量并一定能起到有效的作用，还需要提高系统可并行化程度，即减少系统串行化比重，然后再合理增加处理器的数量，才能达到最佳性价比。根据Amdahl定律，使用并发编程技术解决问题时，系统运行速度的快慢主要取决于CPU或核心的数量及系统中串行化程序的比重。CPU或核心数量越多，串行化比重越低，则系统运行速度越快。仅提高CPU或核心数量而不降低系统串行化程序的比重，也是无法加快系统的运行速度，提高系统的性能。
同时，从上面示例，我们也可以看出，当能并行执行的步骤(2、5)运行速度接近极限（0秒）时，还想提高系统性能，就只能去优化系统的串行步骤(1、3、4)，如使用更高效的算法、采用更快运算速度的处理器，或者再想办法看能否把步骤分解成可以部分并行执行等等方法。这也为我们在优化程序时提供了一些指导思想，使我们能够更加有效的利用并发编程技术。
# 1.2分工原则 
从上一节，我们得知程序从顺序执行转向并发（并行）执行，其效率的提高主要取决于整个系统可并行化程度与处理器(CPU或核心)的数量。现在我们把问题再细化一下，只关注系统中那些可并行的部分(如上一节示例的步骤2与5)，既然这部分能够并行，那我们应该想方设法让它运行的更加快，最好能让它快到接近于0（当然这是不可能的）。这个时候您肯定也想到了一些办法，如增加更多的处理器或用更多核心(128核)的CPU(横向扩展)，又或者更换运算速度更快的CPU(纵向扩展)，这样你就可以开启更多的线程。如果单机性能达到极限(即不能增加更多的CPU或核心数,又不能更换更快速度的CPU时)，你就采用多机，分布式处理等方法让程序能以并行、可伸缩方式运行，目的就是让它跑得更快。现在我们暂不讨论多机、分布式方式，先把问题锁定在单机多核的情况下，因为我们的计算机不可能增加无限多个CPU或核心，通常情况下，都是有限的（4核，8核，16核等）。也就是说，我们在设计并发程序时，只能是在有限的处理器(CPU或核心)数量条件下，启用多个线程或在有些语言中启用多个协程（routine，一种更轻量级的线程）,或在分布式情况启用多个进程的方式来解决问题。那现在就产生了新的问题：启用多个线程，这大概是多少？是否越多越好？如果不是，那应该是多少？它受哪些主要因素的影响？要回答这些问题，我们就从具体问题具体分析开始，先来看看下面两个应用场景：
(1)要求实时计算某土豪所持股票的总资产净值;
(2)计算出[1-2000万]内素数(质数)的个数;
我们先来分析第1个问题，它具体需求是这样的：一些有钱人他可能购买了很多支股票，他想实时查看他这些股票当前的总价值（即总资产净值）是多少，即把他每支股票所拥有的数量乘以当前价格，然后再累加起来就是他所持股票的总资产净值。由于股价是变化的，所以需要程序从一些财经网站（如新浪财经）的股票数据接口中实时获取每支股票的股价。现在我把该问题具体细化成按如下步骤完成：
	输入或导入某土豪所有的股票代号及购买的数量;
	根据每支股票的代号请求财经网站的数据接口获取当前开盘价(假设网站没有提供批量获取股票数据的接口);
	根据每支股票的购买的数量乘以当前开盘价计算出每支股票的价值;
	把步骤3中每支股票的价值求和计算出总价值即总资产净值;
我们先用顺序计算方法实现，现假设某土豪购买了2000支股票(特有钱)，核心代码(JAVA语言)如下(所有代码可从github下载):
 
代码1.1
 
代码1.2
 
代码1.3
其中[代码1.1]的computeNetAssetValue方法就是计算出所有股票的总价值，方法中tickers参数传入所有股票代号,然后遍历每支股票代码，根据股票代码从新浪财经的股票接口中获取当前开盘价[代码1.2]，再乘以购买数量（为了简化问题，假设每支股票他都购买了1000股），最后求和。[代码1.3]的run方法是用来统计程序运行时间及显示计算结果。现在让我们看看程序执行结果(我的笔记本电脑配置是:ThinkPadX240 Intel-i3 1.7G双核4线程,8G内存)，为了减少误差(如网络不稳定、web请求缓存等因素)，我执行了4次，结果如下表所示：
次序	结果	耗时(秒)	CPU（逻辑4核）使用率
第一次	27,309,400.00	35.864706098	3%-10%
第二次	27,309,400.00	34.693427806	2%-10%
第三次	27,309,400.00	34.355382928	3%-10%
第四次	27,309,400.00	34.987066194	2%-10%
从表格中我们看到，每次运行的结果是一致，这说明程序执行过程中没有出现某个请求中断的情况。再看耗时平均在34.5秒左右，这也说明每次执行网络请求与速度是基本稳定的，所以这个结果是可信的。对于这个结果，您可能觉得还行,34.5秒对你来说，这都不是个事儿，咱有的是时间，反正又不着急。但是，如果是一个炒股软件，很多用户都在用，每当他查看总资产净值时需要30多秒（也许客户机器配置好，可能快点），我想客户的心里是很不爽的，因此你为了使客户爽一爽，肯定希望让程序运行得更快些，这个时候你一定会想到用并发执行代替顺序执行，于是就开始进一步分析问题。
	要使用并发（并行）代替顺序执行，我们从上一节就知道，首先这个问题得能并发进行,显然问题1是可以的，我们看看问题1的步骤2与3，这两步中计算每支股票的资产净值是完全独立，也就是说它不依赖其他股票的计算结果,所以这部分就让他并发（并行）执行。既然这样，那我们就快点开始动手吧！哦，等等，有个问题——你打算启用多少个线程来处理它？1个、2个、4个、2000个…,你沉思了片刻，突然说出：4个线程!你当然不是信口开河，你是有依据的，因为你的机器是4核心，少于4个你认为CPU没充分利用（看看顺序执行结果，CPU利用率10%都不到），成百上千的话CPU肯定忙不过来（因为大部分情况在处理线程上下文切换了，自己把自己累死了，这个以后的章节专门讨论），所以4个刚刚好，而且你也知道，同一时刻最多只能4个线程可用(因为CPU是双核4线程)，因此4个也许就是最佳线程数。好！那还等什么呢？马上Coding。很快并发版就搞定，让我们看看[代码1.4]：
 
代码1.4
我们先把计算每支股票的资产净值抽象成一个任务(task)，在代码30-38行把2000支股票资产净值的计算逻辑抽象成2000个任务。然后在代码41行开启多个线程（本例为4个,该处使用JAVA并发包的线程池类,具体用处以后章节讨论），代码42行开始并发调用2000个任务,代码45-48行阻塞程序主线程直到所有任务都处理完成并把每个任务的计算结果进行汇总。我们同样执行4次，看看结果如下表所示：
次序	结果	耗时(秒)/4线程	CPU（逻辑4核）使用率
第一次	27,309,400.00	8.551527841	5%-20%
第二次	27,309,400.00	8.467957693	3%-25%
第三次	27,309,400.00	8.612325121	6%-21%
第四次	27,309,400.00	8.563007854	7%-20%
从上表结果列中可以看出程序改成并发后结果与顺序执行是一致，这说明程序逻辑上没有问题，是正确的。再看耗时，哇！快了4倍，你欣喜若狂，8.5秒，2000个任务，每秒处理了240多个任务,而且这似乎也印证了你之前的结论，顺序执行时，每秒大概处理了60多个请求，相当于一个CPU核心能处理60多请求，现在CPU是4核并行，理论上应该是顺序执行的4倍，现在刚好也是4倍，你可能认为这应该是最佳结果了，因为同一时刻只能有4核心一起工作，而每个核心处理能力的上限是每秒60个任务，现在执行的结果与我们的分析也相符合，所以你可能就得出一个经验：就是在设计并发程序时，线程个数应该与CPU或核心的数量相当，这样就可以达到最佳并发效果。但是我们忽略了一个事情:你是否发现CPU的利用率还很低，最高只有25%，这说明CPU还比较闲，还没充分使用CPU,程序应该还能更快点。那我们再多开启一些线程试试，[图1.4]显示了线程数量与程序运行时间的关系(横轴为线程数，纵轴为执行时间):
 图1.4
从上图我们发现，原来程序真的还能更快些，接近2秒就能处理完2000个任务,与顺序执行相比快了15倍，有时真的不敢相信自己的眼睛，程序1秒钟就能完成800-1000支股票的计算任务，这与之前分析的单个核心的上限是每秒60个任务不相符，因为现在达到每秒200多个任务(800/4核心)，那这又是什么原因呢？而且线程数量也不是越多越快，而是达到一定的量之后运行时间趋于稳定,也就是说不能再快了。我先暂且不回答这个问题，读者可以再仔细想想。接下来我们要分析第2个问题。
	
# 1.3有效的并发策略 
	
# 1.4小结 

# 1.5后记

# 1.6参考资料


[java]: http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html  
[C#]: https://msdn.microsoft.com/zh-cn/library/67ef8sbd.aspx 
[ruby]: https://www.ruby-lang.org/en/ 
[scala]: http://www.scala-lang.org/documentation/ 
[go]: http://golang.org/doc/ 
[akka]: http://akka.io/ 
[actor]: http://de.wikipedia.org/wiki/Actor_Model 
[reactor]: http://en.wikipedia.org/wiki/Reactor_pattern 
[proactor]: http://en.wikipedia.org/wiki/Proactor_pattern 
[epoll]: http://en.wikipedia.org/wiki/Epoll 
[Amdahl定律]: http://en.wikipedia.org/wiki/Amdahl%27s_law 
[素数]: http://baike.baidu.com/view/10626.htm 
[总资产净值]: http://baike.baidu.com/view/268755.htm 
[新浪财经]: http://vip.stock.finance.sina.com.cn/mkt/#sh_a  
[github]: https://github.com/xianrendzw/ConcurrentProgramming 